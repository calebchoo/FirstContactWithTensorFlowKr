 CLOSING
 +마치며
  
  Exploration is the engine that drives innovation. Innovation drives economic growth. So let’s all go exploring.
 -
 +탐험은 혁신으로 이끄는 엔진입니다. 혁신은 경제 성장을 이끕니다. 자 우리 모두 함께 탐험을 떠납시다. 
  Edith Widder
 -
 +에디쓰 위더(TED 2013 "우리가 어떻게 거대 오징어를 발견했는가?" 발표자. 해양학자이며 발명가)
   
   
  Here I have presented an introductory guide explaining how to use TensorFlow, providing a warm-up with this technology that will undoubtedly have a leading role in the looming technological scenario. There are, indeed, other alternatives to TensorFlow, and each one suit the best a particular problem; I want to invite the reader to explore beyond the TensorFlow package.
 +여기에 나는 텐서플로우를 어떻게 사용할 것인지를 설명하는 입문 가이드를 제시했으며, 어렴풋한 기술적인 시나리오 안에서 의심의 여지 없이 하나의 선도적인 역할을 하게 될 이 기술에 대한 워밍업을 제공했다.
 
There is lots of diversity in these packages. Some are more specialized, others less. Some are more difficult to install than others. Some of them are very well documented while others , despite working well, are more difficult to find detailed information about how to use them.
이러한 유형의 패키지들에는 매우 많은 다양성이 있다. 일부는 더 많이 특화되어 있으며, 다른 것들은 덜 특화되어 있다. 일부는 다른 것들보다 설치하기 더 많이 어렵다. 그들 중 일부는 매우 잘 문서화 되어 있지만 다른 것들은 잘 작동함에도 불구하고 어떻게 사용하는지에 대한 자세한 정보를 찾기 어렵다.

An important thing: on the following day that TensorFlow was release by Google, I read in a tweet[49] that during the period 2010-2014 a new Deep learning package was released every 47 days, and in 2015 releases were published every 22 days. It is mpressive, isn’t it? As I advanced in the first chapter of the book, as a starting point for the reader, an extensive list can be found at Awesome Deep Learning[50].
한가지 중요한 사실: 구글에 의해 텐서플로우가 배포된 다음날 나는 트위터[49]에서 2010-2014 기간 중에 새로운 딥러닝 패키지가 매 47일마다 배포되었고, 2015년도에는 매 22일마다 배포판이 나왔다. 이것은 인상적인 일이다, 그렇지 않은가? 내가 책의 첫번째 장에서 독자의 시작 지점으로써 미리 말한대로, Awesome Deep Learning[50]에서 광대한 딥러닝 패키지 목록을 찾을 수 있다.


Without any doubt, the landscape of Deep Learning was impacted in November 2015 with the release of Google’s TensorFlow, being now the most popular open source machine learning library on Github by a wide margin[51].

Remember that the second most-starred Machine Learning project of Github is Scikit-learn[52], the de facto official Python general Machine Learning framework. For these users, TensorFlow can be used through Scikit Flow (skflow)[53], a simplified interface for TensorFlow coming out from Google.

Practically, Scikit Flow is a high level wrapper for the TensorFlow library, which allows the training and fitting of neural networks using the familiar approach of Scikit-Learn. This library covers a variety of needs from linear models to Deep Learning applications.

In my humble opinion, after the release of the distributed version of TensorFlow, TensorFlow Serving and Scikit Flow, TensorFlow will become de facto a mainstream Deep Learning library.

Deep learning has dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains. What will be its future? According to an excellent review from Yann LeCun, Yoshua Bengio and Geoffrey Hilton in Nature journal, the answer is the Unsupervised Learning [54]. They expect Unsupervised Learning to become far more important in longer term than supervised learning. As they mention, human and animal learning is largely unsupervised: we discover the structure of the world by observing it, not by being told the name of every object.

They have a lot of espectations of the future progress of the systems that combine CNN with recurrent neural network (RNN) that use reinforcement learning. RNNs process an input that sequence one element at time, maintaining in their hidden units information about the history of all the past elements of the sequence. For an introduction to RNN implementation in TensorFlow the reader can review the Recurrent Neural Networks [55] section in TensorFlow Tutorial.

Besides, there are many challenges ahead in Deep Learning; the time to training them are driving the need for a new class of supercomputer systems. A lot of research is still necessary in order to integrate the best analytics knowledge with new Big Data technologies and the awesome power of emerging computational systems in order to interpret massive amounts of heterogeneous data at an unprecedented rate.

Scientific progress is typically the result of an interdisciplinary, long and sustained effort by a large community rather than a breakthrough, and deep learning, and machine learning in general, is not an exception. We are entering into an extremely exciting period for interdisciplinary research, where ecosystems like the ones found in Barcelona as UPC and BSC-CNS, with deep knowledge in High Performance Computing and Big Data Technologies, will play a big role in this new scenario.

[contents link]
